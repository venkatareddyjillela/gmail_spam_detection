{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# -*- coding: utf-8 -*-\n", "\"\"\"GMAIL SPAM DETECTION"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["Automatically generated by Colaboratory."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["Original file is located at\n", "    https://colab.research.google.com/drive/1FyD7r2jNsFiDB1-CtWjkk4MyRjLwAZLE\n", "\"\"\""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["!pip install nltk"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import numpy as np\n", "import pandas as pd\n", "import nltk"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["data = pd.read_csv('spam.csv', encoding= 'unicode_escape')\n", "data.head()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["data['spam'] = data['type'].map({'spam':1,'ham':0}).astype(int)\n", "data.head()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["print(\"columns in data\")\n", "for c in data.columns:\n", "  print(c)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["l = len(data['type'])\n", "print('no of rows in review column',l)\n", "l = len(data['text'])\n", "print('no of rows in review column',l)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["data['text'][1]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def tokenizer(text):\n", "  return text.split()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["data['text']  = data['text'].apply(tokenizer)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["data.head()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from nltk.stem.snowball import  SnowballStemmer\n", "porter = SnowballStemmer('english',ignore_stopwords=False)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def stem_it(text):\n", "  return [porter.stem(word) for word in text]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["data['text'] = data['text'].apply(stem_it)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["data['text'][34]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from nltk.stem import WordNetLemmatizer\n", "lemmatizer = WordNetLemmatizer()\n", "nltk.download('wordnet')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def lemit(text):\n", "  return [lemmatizer.lemmatize(word,pos='a') for word in text]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["data['text'] = data['text'].apply(lemit)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["data['text'][23]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["nltk.download('stopwords')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from nltk.corpus import stopwords\n", "  stop_words = stopwords.words('english')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def stop(text):\n", "  review = [word for word in text if not word in stop_words]\n", "  return review"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["data['text'] = data['text'].apply(stop)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["data.head()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["data['text'] = data['text'].apply(' '.join)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["data.head()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.feature_extraction.text import TfidfVectorizer"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["tfidf = TfidfVectorizer()\n", "y = data.spam.values\n", "x = tfidf.fit_transform(data['text'])"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.model_selection import train_test_split\n", "x_train,x_test,y_train,y_test = train_test_split(x,y,random_state = 1,test_size = 0.2,shuffle = False)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.linear_model import LogisticRegression\n", "clf = LogisticRegression()\n", "clf.fit(x_train,y_train)\n", "y_pred = clf.predict(x_test)\n", "from sklearn.metrics import accuracy_score\n", "acc_log = accuracy_score(y_pred,y_test)*100\n", "print(\"accuracy score\",acc_log)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["from sklearn.svm import LinearSVC\n", "linear_svc = LinearSVC(random_state=0)\n", "linear_svc.fit(x_train,y_train)\n", "y_pred = linear_svc.predict(x_test)\n", "acc_linear_svc = accuracy_score(y_pred,y_test)*100\n", "print(\"accuracy score\",acc_linear_svc)"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}